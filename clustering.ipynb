{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing original dataset via CSV (https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset)\n",
    "import pandas as pd\n",
    "def load_dataset(csv):\n",
    "  df = pd.read_csv('online_shoppers_intention.csv')\n",
    "  return df\n",
    "csv = 'online_shoppers_intention.csv'\n",
    "df = load_dataset(csv)\n",
    "\n",
    "#Feature Engineering\n",
    "#Converting Categorical into Integers and Use One-Hot Coding\n",
    "sessions = df\n",
    "sessions['Revenue'] = sessions['Revenue'].astype(int)#converting revenue into 0 and 1\n",
    "sessions['SpecialDay'] = sessions['SpecialDay'].astype(int)\n",
    "# One-hot encode VisitorType\n",
    "visitor_type_dummies = pd.get_dummies(sessions['VisitorType'], prefix='VisitorType').astype(int)\n",
    "sessions = pd.concat([sessions, visitor_type_dummies], axis=1)\n",
    "sessions.drop('VisitorType', axis=1, inplace=True)\n",
    "sessions['Weekend']=sessions['Weekend'].astype(int)\n",
    "sessions['Month'] = sessions['Month'].map({'Feb':2, 'Mar':3,'May':5, 'June':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12})\n",
    "\n",
    "#Adding Relevant Columns\n",
    "sessions['SessionDuration']=sessions['Administrative_Duration']+sessions['Informational_Duration']+sessions['ProductRelated_Duration']\n",
    "sessions['TotalPagesViewed']=sessions['Administrative']+sessions['Informational']+sessions['ProductRelated']\n",
    "sessions['BounceRates'] = sessions['BounceRates'].astype(float)\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many K Means we should use with Elbow Method\n",
    "\n",
    "def elbow_method(data, max_k):\n",
    "  inertias = []\n",
    "  for i in range(1, max_k):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(data)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "  plt.plot(range(1, max_k), inertias, 'o-')\n",
    "  plt.title('Elbow Method')\n",
    "  plt.xlabel('Number of clusters')\n",
    "  plt.ylabel('Inertia')\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "elbow_method(sessions, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_centroids(data, k):\n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        centroid = data.apply(lambda x: float(x.sample()))\n",
    "        centroids.append(centroid)\n",
    "    return pd.concat(centroids, axis=1)\n",
    "\n",
    "def get_labels(data, centroids):\n",
    "    distances = centroids.apply(lambda x: np.sqrt(((data - x) ** 2).sum(axis=1)))\n",
    "    return distances.idxmin(axis=1)\n",
    "\n",
    "def new_centroids(data, labels, k):\n",
    "    centroids = data.groupby(labels).apply(lambda x: np.exp(np.log(x).mean())).T\n",
    "    return centroids\n",
    "\n",
    "def plot_clusters(data, labels, centroids, iteration):\n",
    "    pca = PCA(n_components=2)\n",
    "    data_2d = pca.fit_transform(data)\n",
    "    centroids_2d = pca.transform(centroids.T)\n",
    "    clear_output(wait=True)\n",
    "    plt.title(f'Iteration {iteration}')\n",
    "    plt.scatter(x=data_2d[:,0], y=data_2d[:,1], c=labels)\n",
    "    plt.scatter(x=centroids_2d[:,0], y=centroids_2d[:,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_12780\\748041225.py:4: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  centroid = data.apply(lambda x: float(x.sample()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    5035\n",
       "5    3985\n",
       "2    2737\n",
       "1     497\n",
       "0      76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_of_k = 6\n",
    "centroids = random_centroids(sessions, value_of_k)\n",
    "labels = get_labels(sessions, centroids)\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 100\n",
    "centroid_count = value_of_k\n",
    "\n",
    "centroids = random_centroids(sessions, centroid_count)\n",
    "old_centroids = pd.DataFrame()\n",
    "iteration = 1\n",
    "\n",
    "while iteration < max_iterations and not centroids.equals(old_centroids):\n",
    "    old_centroids = centroids\n",
    "    \n",
    "    labels = get_labels(sessions, centroids)\n",
    "    centroids = new_centroids(sessions, labels, centroid_count)\n",
    "    plot_clusters(sessions, labels, centroids, iteration)\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy\\stats\\_stats_py.py:4102: DegenerateDataWarning: at least one input has length 0\n",
      "  if _f_oneway_is_too_small(samples):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features: {}\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop through each feature in the sessions DataFrame\n",
    "for feature in sessions.columns:\n",
    "    if feature != 'labels':\n",
    "        # Perform ANOVA for the current feature across all centroids\n",
    "        p_value = stats.f_oneway(*[sessions[sessions['labels'] == i][feature] for i in range(value_of_k)])[1]\n",
    "        # Store the p-value in the results dictionary\n",
    "        results[feature] = p_value\n",
    "\n",
    "# Initialize an empty dictionary to store significant features\n",
    "significant_features = {}\n",
    "\n",
    "# Loop through the results dictionary\n",
    "for feature, p_value in results.items():\n",
    "    # Check if the p-value is less than 0.05\n",
    "    if p_value < 0.05:\n",
    "        # Add the feature to the significant_features dictionary\n",
    "        significant_features[feature] = p_value\n",
    "\n",
    "# Print the significant features\n",
    "print(\"Significant Features:\", significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features: {'Administrative': 0.0, 'Administrative_Duration': 0.0, 'Informational': 9.758683011124056e-303, 'Informational_Duration': 0.0, 'ProductRelated': 0.0, 'ProductRelated_Duration': 0.0, 'BounceRates': 0.0, 'ExitRates': 0.0, 'PageValues': 2.0786277299896437e-69, 'SpecialDay': 0.018612362598686098, 'Month': 7.968736520034775e-48, 'TrafficType': 2.9129139811946957e-08, 'Weekend': 0.0022962125580584794, 'Revenue': 2.850819539483301e-113, 'VisitorType_New_Visitor': 3.22111047471983e-50, 'VisitorType_Other': 1.1997513483115759e-05, 'VisitorType_Returning_Visitor': 1.4068193938878273e-53, 'SessionDuration': 0.0, 'TotalPagesViewed': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Initialize an empty dictionary to store p-values for each feature\n",
    "results = {}\n",
    "\n",
    "# Loop through each feature in the DataFrame, excluding the 'labels' column\n",
    "for feature in sessions.columns:\n",
    "    if feature != 'labels':\n",
    "        # Gather data for the feature across all non-empty clusters\n",
    "        feature_data = [sessions[labels == i][feature] for i in range(value_of_k) if len(sessions[labels == i]) > 0]\n",
    "        \n",
    "        # Ensure there are enough samples per group for ANOVA (at least two non-empty groups)\n",
    "        if all(len(data) > 1 for data in feature_data) and len(feature_data) > 1:\n",
    "            # Perform ANOVA for the current feature across all centroids\n",
    "            stat, p_value = stats.f_oneway(*feature_data)\n",
    "            # Store the p-value in the results dictionary\n",
    "            results[feature] = p_value\n",
    "        else:\n",
    "            print(f\"Not enough data for ANOVA in feature '{feature}'\")\n",
    "\n",
    "# Initialize a dictionary to store only the significant features\n",
    "significant_features = {feature: p_value for feature, p_value in results.items() if p_value < 0.05}\n",
    "\n",
    "# Print the significant features\n",
    "print(\"Significant Features:\", significant_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39       0.0\n",
       "75       0.0\n",
       "117      0.0\n",
       "147      0.0\n",
       "160      0.0\n",
       "        ... \n",
       "12241    0.0\n",
       "12254    0.0\n",
       "12298    0.0\n",
       "12324    0.0\n",
       "12326    0.0\n",
       "Name: PageValues, Length: 497, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify individual sessions in the columns \n",
    "features=['Revenue', 'SessionDuration', 'TotalPagesViewed', 'BounceRates', 'ExitRates', 'PageValues', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'Weekend', 'VisitorType_New_Visitor', 'VisitorType_Other', 'VisitorType_Returning_Visitor']\n",
    "#features=['Revenue', 'SessionDuration', 'TotalPagesViewed', 'BounceRates', 'ExitRates', 'PageValues', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'Weekend', 'VisitorType']\n",
    "\n",
    "#View the values in each Cluster if meaningful*\n",
    "print(sessions[labels==1]['PageValues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(6)\n",
    "kmeans.fit(sessions)\n",
    "sk_centroids=kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_labels = get_labels(sessions, pd.DataFrame(sk_centroids).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features: {'Administrative': 0.0, 'Administrative_Duration': 0.0, 'Informational': 0.0, 'Informational_Duration': 0.0, 'ProductRelated': 0.0, 'ProductRelated_Duration': 0.0, 'BounceRates': 1.7872193668700428e-133, 'ExitRates': 1.4684121613067783e-274, 'PageValues': 1.0594980807316606e-35, 'Month': 1.3683604593730615e-59, 'Region': 0.003979309260472367, 'TrafficType': 1.1403300340276675e-05, 'Revenue': 1.22952009743693e-81, 'VisitorType_New_Visitor': 2.7835625267847577e-54, 'VisitorType_Other': 0.016681381413509125, 'VisitorType_Returning_Visitor': 7.211993899974316e-58, 'SessionDuration': 0.0, 'TotalPagesViewed': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Get the labels from the kmeans object\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Loop through each feature in the sessions DataFrame\n",
    "for feature in sessions.columns:\n",
    "    if feature != 'labels':\n",
    "        # Perform ANOVA for the current feature across all centroids\n",
    "        p_value = stats.f_oneway(*[sessions[kmeans_labels == i][feature] for i in range(value_of_k)])[1]\n",
    "        # Store the p-value in the results dictionary\n",
    "        results[feature] = p_value\n",
    "\n",
    "# Initialize an empty dictionary to store significant features\n",
    "significant_features = {}\n",
    "\n",
    "# Loop through the results dictionary\n",
    "for feature, p_value in results.items():\n",
    "    # Check if the p-value is less than 0.05\n",
    "    if p_value < 0.05:\n",
    "        # Add the feature to the significant_features dictionary\n",
    "        significant_features[feature] = p_value\n",
    "\n",
    "# Print the significant features\n",
    "print(\"Significant Features:\", significant_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
